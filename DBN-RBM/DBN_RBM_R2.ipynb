{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DBN-RBM R2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data Analyst for LQ 45 to Find Financial Destress Saham**"
      ],
      "metadata": {
        "id": "R3Fbw1v0vZgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RBM MODELING**"
      ],
      "metadata": {
        "id": "2_BY4pOnkoYO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLXeNapGvWhG"
      },
      "outputs": [],
      "source": [
        "#Import Library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Dataset Saham 2019\n",
        "dataset = pd.read_excel(\"2019-1.xlsx\")"
      ],
      "metadata": {
        "id": "77Cj17Xav4Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete Columns Kode and Nama Saham\n",
        "data = dataset.drop(['Kode','Nama Saham'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "061qZKbpwPaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change dataset to Array\n",
        "new_data = np.array(dataset,dtype='int')"
      ],
      "metadata": {
        "id": "HbfCXVduxBHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Dataset to training_set and test_set \n",
        "from sklearn.model_selection import train_test_split\n",
        "training_set,test_set = train_test_split(new_data,test_size=0.5)"
      ],
      "metadata": {
        "id": "aSTNAaxExp9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set"
      ],
      "metadata": {
        "id": "m76BdrQDz3DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set"
      ],
      "metadata": {
        "id": "mGHQDISIzv07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take max id_saham in train and test data\n",
        "nb_saham = int(max(max(training_set[:, 0]), max(test_set[:, 0])))"
      ],
      "metadata": {
        "id": "KhfN-XDKz9I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of saham\n",
        "nb_saham"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IKZDKae0DhY",
        "outputId": "f6108ea5-6ca7-4969-f314-e01d1127c0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to tensor data from array\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "4YZsG9X90ZVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set"
      ],
      "metadata": {
        "id": "kHLL7Nz90cSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set"
      ],
      "metadata": {
        "id": "SKqesALC0h8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data from -1 to 1\n",
        "training_set[training_set <= 0] = -1\n",
        "training_set[training_set == 0] = 0\n",
        "training_set[training_set >= 1] = 1\n",
        "\n",
        "test_set[test_set <= 0] = -1\n",
        "test_set[test_set == 0] = 0\n",
        "test_set[test_set >= 1] = 1\n"
      ],
      "metadata": {
        "id": "eVmJXgRX0y9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set"
      ],
      "metadata": {
        "id": "zl8kG9Sb1CuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set"
      ],
      "metadata": {
        "id": "r-uEGZDr1IEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODELING V1**"
      ],
      "metadata": {
        "id": "LJovSdmMBW_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RBM Architecture Creation**"
      ],
      "metadata": {
        "id": "HmE1NwHh_u2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM():\n",
        "    def __init__(self, nv, nh):\n",
        "        ##initialize all weights \n",
        "        ##a tensor with size of nh, nv in normal dis mean 0 var 1\n",
        "        self.W = torch.randn(nh, nv)\n",
        "        #bias for hidden nodes\n",
        "        #1st dimension is batch, 2nd is num of hidden nodes\n",
        "        self.a = torch.randn(1, nh)\n",
        "        #bias for visible nodes\n",
        "        self.b = torch.randn(1, nv)\n",
        "    #activate the hidden nodes by sampling all hiddens node, given values of visible nodes \n",
        "    def sample_h(self, x):\n",
        "        #x is values of visible nodes\n",
        "        #probablity of hiddens h to be activated, given values of visible  nodes v\n",
        "        wx = torch.mm(x, self.W.t())\n",
        "        #use sigmoid fuc to activate visible node\n",
        "        ## a is bias for hidden nodes\n",
        "        activation = wx + self.a.expand_as(wx)\n",
        "        ##ith of the vector is the probability of ith hidden nodes to be activated, \n",
        "        ##given visible values\n",
        "        p_h_given_v =torch.sigmoid(activation)\n",
        "        #samples of all hiddens nodes\n",
        "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "    def sample_v(self, y):\n",
        "        #y is hidden nodes\n",
        "        #probablity of visible h to be activated, given hidden  nodes v\n",
        "        wy = torch.mm(y, self.W)\n",
        "        #use sigmoid fuc to activate hiddens nodes\n",
        "        activation = wy + self.b.expand_as(wy)\n",
        "        ##ith of the vector is the probability of ith visible nodes to be activated, \n",
        "        ##given hidden values\n",
        "        p_v_given_h =torch.sigmoid(activation)\n",
        "        #samples of all hiddens nodes\n",
        "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "        \n",
        "    #visible nodes after kth interation\n",
        "    #probablity of hidden nodes after kth iteration\n",
        "    def train(self, v0, vk, ph0, phk):\n",
        "#         self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)\n",
        "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "#         self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)\n",
        "        #add zero to keep b as a tensor of 2 dimension\n",
        "        self.b += torch.sum((v0 - vk), 0)\n",
        "        self.a += torch.sum((ph0 - phk), 0)\n",
        "   "
      ],
      "metadata": {
        "id": "bGSKcmys1Pac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize RBM object"
      ],
      "metadata": {
        "id": "Xm3tbXn4_085"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#number of visible node = 12\n",
        "nv = len(training_set[0])\n",
        "#number of hidden nodes or num of features\n",
        "nh = 100\n",
        "batch_size = nb_saham-1\n",
        "rbm = RBM(nv, nh)"
      ],
      "metadata": {
        "id": "ncWF9kPK1TkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training**"
      ],
      "metadata": {
        "id": "ErG7Ae1HAAHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epoch = 5\n",
        "for epoch in range(1, nb_epoch+1):\n",
        "    ##loss function\n",
        "    train_loss = 0\n",
        "    #normalize the loss, define a counter\n",
        "    s = 0.\n",
        "    #implement a batch learning, \n",
        "    for id_saham in range(0, nb_saham - batch_size, 10):\n",
        "        #input batch values\n",
        "        vk = training_set[id_saham: id_saham+batch_size]\n",
        "        #target used for loss mesarue: data \n",
        "        v0 = training_set[id_saham: id_saham+batch_size]\n",
        "        ##initilize probablity\n",
        "        #pho: given real rating at begining, probablity of hidden nodes\n",
        "        ph0, _ = rbm.sample_h(v0)\n",
        "        #k step of constrative divergence\n",
        "        for k in range(10):\n",
        "            _, hk = rbm.sample_h(vk)\n",
        "            _, vk = rbm.sample_v(hk)\n",
        "            #training on rating that do exist, rating as -1\n",
        "            vk[v0<0] = v0[v0<0]\n",
        "        phk, _ = rbm.sample_h(vk)\n",
        "        #update weights and bias\n",
        "        rbm.train(v0, vk, ph0, phk)\n",
        "        #update train loss\n",
        "        train_loss += torch.mean(torch.abs(v0[v0>0]-vk[v0>0]))\n",
        "        s += 1\n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWAI2--R1YU1",
        "outputId": "994c781d-7353-4256-c403-0ce96c166cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: tensor(0.0123)\n",
            "epoch: 2 loss: tensor(0.0184)\n",
            "epoch: 3 loss: tensor(0.0307)\n",
            "epoch: 4 loss: tensor(0.0184)\n",
            "epoch: 5 loss: tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test RBM**"
      ],
      "metadata": {
        "id": "uuqPuX5DAOT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##loss function test\n",
        "test_loss = 0\n",
        "#normalize the loss, define a counter\n",
        "s = 0.\n",
        "#implement a batch learning, \n",
        "for id_saham in range(0,nb_saham-len(test_set)):\n",
        "    #use input of train set to activate RBM\n",
        "    v_input = training_set[id_saham: id_saham+1]\n",
        "    #target used for loss mesarue:  \n",
        "    v_target = test_set[id_saham: id_saham+1]\n",
        "    #use only 1 step to make better prediction, though used 10 steps to train\n",
        "    if len(v_target[v_target>=0]):\n",
        "        _, h = rbm.sample_h(v_input) \n",
        "        _, v_input = rbm.sample_v(h)\n",
        "        #update test loss\n",
        "        test_loss += torch.mean(torch.abs(v_target[v_target>0]-v_input[v_target>0]))\n",
        "        s += 1.\n"
      ],
      "metadata": {
        "id": "cS_2LLLKiaJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('test loss: ' +str(test_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKNxuGPEkCwx",
        "outputId": "a422824b-a618-4ba7-8144-0d94d94d03ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: tensor(0.0652)\n"
          ]
        }
      ]
    }
  ]
}